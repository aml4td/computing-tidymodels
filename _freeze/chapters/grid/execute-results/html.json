{
  "hash": "967753cc9e05f75342dda51eb69aa2ce",
  "result": {
    "engine": "knitr",
    "markdown": "---\nknitr:\n  opts_chunk:\n    cache.path: \"../_cache/grid/\"\n---\n\n\n\n\n# Grid Search {#sec-grid}\n\nThe previous chapters have discussed how to estimate performance using resampling as well as how to tag arguments for optimization (via `tune()`). This page will illustrate how to use similar tools to optimize models via grid search. \n\n\n\n\n\n\n\n\n\n\n\n## Requirements\n\nAs with the previous chapter, we will use the `concrete` data set from the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=modeldata\">modeldata</a></span> package (which is automatically loaded below) to illustrate some of the methods.\n\nYou’ll need 4 packages (<span class=\"pkg\"><a href=\"https://cran.r-project.org/package=Cubist\">Cubist</a></span>, <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=finetune\">finetune</a></span>, <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=rules\">rules</a></span>, and <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=tidymodels\">tidymodels</a></span>) for this chapter. \nYou can install them via:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreq_pkg <- c(\"Cubist\", \"finetune\", \"rules\", \"tidymodels\")\n\n# Check to see if they are installed: \npkg_installed <- vapply(req_pkg, rlang::is_installed, logical(1))\n\n# Install missing packages: \nif ( any(!pkg_installed) ) {\n  install_list <- names(pkg_installed)[!pkg_installed]\n  pak::pak(install_list)\n}\n```\n:::\n\n\n\n\nLet's load the meta package and manage some between-package function conflicts. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\ntheme_set(theme_bw())\n```\n:::\n\n\n\n\n## Creating Grids {#sec-grid-creation}\n\nThe <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=dials\">dials</a></span> package has several grid creation functions, whose names all start with grid_. The primary input is a <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=dials\">dials</a></span> parameter set object, which can be created from a model, recipe, or workflow. The primary functions are: \n\n - `grid_regular()` for regular grids. The argument for specifying the size of the grid is called `levels`. This can be a single number (recycled across parameters) or a vector of sizes for each tuning parameter. \n - `grid_random()` creates random uniform parameter values. The argument `size` dictates how many candidate combinations are created. \n - `grid_space_filling()` can produce different types of space-filling designs (via the `type` argument). It also uses a `size` argument. \n\nLet’s pick back up from the Cubist example in @sec-resampled-models. We can tag two of the Cubist models’s parameters for tuning: \n\n - The number of `committee` members in the ensemble (usually ranging from one to 100). \n - The number of `neighbors` to use in a post hoc model adjustment phase, ranging from zero neighbors (i.e., no adjustment) to nine. \n\nBoth of these parameters are described more in a blog post on [\"Modern Rule-Based Models\"](https://rviews.rstudio.com/2020/05/21/modern-rule-based-models/).  \n\nWe need to load the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=rules\">rules</a></span> package to enable access to the model, mark these parameters for tuning, and then extract the parameter set needed to make the grids. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(rules)\n\ncubist_spec <- cubist_rules(committees = tune(), neighbors = tune())\n\ncubist_param <- \n  cubist_spec %>% \n  extract_parameter_set_dials()\n\ncubist_param\n#> Collection of 2 parameters for tuning\n#> \n#>  identifier       type    object\n#>  committees committees nparam[+]\n#>   neighbors  neighbors nparam[+]\n```\n:::\n\n\n\n\nLet's make a uniform space-filling design with 25 candidate models: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncubist_grid <- grid_space_filling(cubist_param, size = 25) \n\ncubist_grid %>% \n  ggplot(aes(committees, neighbors)) + \n  geom_point() + \n  coord_fixed(ratio = 10)\n```\n\n::: {.cell-output-display}\n![](../figures/cubist-grid-1.svg){fig-align='center' width=40%}\n:::\n:::\n\n\n\n\nRecall from @sec-tuning-parameters, we can manipulate the ranges and values of the tuning parameters in the parameter set using `update()`. \n\nNote that: \n\n - If we labeled any of our parameters (e.g., `neighbors = tune(\"K\")`), that label is used as the column name.\n - Some parameters are associated with a transformation, and, by default, the values are created on that scale and then transformed back to the original units when the grid is returned. \n - The `size` argument should be considered the _maximum_ size; redundant combinations are removed. For example:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Default range is 0L to 9L:\ncubist_rules(neighbors = tune(\"K\")) %>% \n  extract_parameter_set_dials() %>%\n  grid_space_filling(size = 50) %>% \n  arrange(K)\n#> # A tibble: 10 × 1\n#>       K\n#>   <int>\n#> 1     0\n#> 2     1\n#> 3     2\n#> 4     3\n#> 5     4\n#> 6     5\n#> # ℹ 4 more rows\n```\n:::\n\n\n\n\nYou can also make grid manually as long as they are in a data frame and the column names match the parameter types/labels of the parameters: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncrossing(committees = c(1, 8, 100), neighbors = c(0, 9))\n#> # A tibble: 6 × 2\n#>   committees neighbors\n#>        <dbl>     <dbl>\n#> 1          1         0\n#> 2          1         9\n#> 3          8         0\n#> 4          8         9\n#> 5        100         0\n#> 6        100         9\n```\n:::\n\n\n\n\nFinally, as a reminder, a workflow can contain preprocessing arguments that were tagged for optimization via `tune()`. These values are treated the same as model arguments when it comes to extracting the parameter set and creating grids. \n\n## Tuning Models with Grids {#sec-grid-tuning}\n\nFor grids, the three main functions are `tune::tune_grid()` and the two racing functions in the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=finetune\">finetune</a></span> package: `finetune::tune_race_anova()` and `finetune::tune_race_winloss()`. The syntax for these is nearly identical and also closely follows the previously described code for `fit_resamples()` from @sec-resampled-models.\n\nThe primary arguments for these tuning functions in tidymodels are: \n\n - `grid`: Either a data frame or an integer value. The latter choice will trigger tidymodels to make a space-filling design for you. \n - `param_info`: The parameter set object. This is only needed if `grid` is an integer and you request nonstandard ranges/values for one or more parameters. \n \nOther arguments, such as `metrics`, are the same. The control function for these functions are named differently (e.g., `tune_race()`). \n\nTo get started, let’s recreate the objects for the concrete data that match those from the previous chapter: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(426)\nconcrete_split <- initial_split(concrete, prop = 3 / 4)\nconcrete_tr <- training(concrete_split)\nconcrete_te <- testing(concrete_split)\nconcrete_rs <- vfold_cv(concrete_tr)\n```\n:::\n\n\n\n\nWe will reuse the `cubist_spec` and `cubist_grid` objects created above. \n\nLet's do basic grid search: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncubist_res <- \n  cubist_spec %>% \n  tune_grid(\n    compressive_strength ~ .,\n    resamples = concrete_rs,\n    grid = cubist_grid,\n    control = control_grid(save_pred = TRUE, save_workflow = TRUE)\n  )\n```\n:::\n\n\n\n\nThe option to save the workflow for our model will be references below. \n\nThis object is similar to the one produced by fit_resamples except that the `.metrics` and `.predictions` columns have more rows since their values contain the results for the 25 candidates. We have our previous functions to rely on: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncollect_metrics(cubist_res)\n#> # A tibble: 50 × 8\n#>   committees neighbors .metric .estimator   mean     n  std_err .config             \n#>        <int>     <int> <chr>   <chr>       <dbl> <int>    <dbl> <chr>               \n#> 1          1         4 rmse    standard   5.785     10 0.2373   Preprocessor1_Model…\n#> 2          1         4 rsq     standard   0.8828    10 0.01024  Preprocessor1_Model…\n#> 3          5         2 rmse    standard   5.004     10 0.2625   Preprocessor1_Model…\n#> 4          5         2 rsq     standard   0.9103    10 0.009437 Preprocessor1_Model…\n#> 5          9         7 rmse    standard   5.011     10 0.1992   Preprocessor1_Model…\n#> 6          9         7 rsq     standard   0.9105    10 0.007576 Preprocessor1_Model…\n#> # ℹ 44 more rows\ncollect_predictions(cubist_res)\n#> # A tibble: 19,300 × 7\n#>    .pred id      .row committees neighbors compressive_strength .config             \n#>    <dbl> <chr>  <int>      <int>     <int>                <dbl> <chr>               \n#> 1 41.63  Fold01     8          1         4                40.76 Preprocessor1_Model…\n#> 2 29.84  Fold01    14          1         4                29.22 Preprocessor1_Model…\n#> 3 37.52  Fold01    27          1         4                37.36 Preprocessor1_Model…\n#> 4 24.99  Fold01    38          1         4                20.73 Preprocessor1_Model…\n#> 5 62.37  Fold01    53          1         4                55.16 Preprocessor1_Model…\n#> 6  9.835 Fold01    71          1         4                 9.74 Preprocessor1_Model…\n#> # ℹ 19,294 more rows\n```\n:::\n\n\n\n\nThere are a few additional methods that we can apply here. First, we can visualize the results using `autoplot()`: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(cubist_res)\n```\n\n::: {.cell-output-display}\n![](../figures/cubist-autoplot-1.svg){fig-align='center' width=75%}\n:::\n:::\n\n\n\n\nThis function has a `metric` argument in case you want to plot a selection of metrics. Also, for regular grids, the visualization can look very different. \n\nFrom these results, both tuning parameters have an effect on performance. A small number of committees or neighbors have poor performance. How can we tell which one was best for either metric? \n\nThere are also `show_best()` and `select_*()` functions to select the best results _for a given metric_: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nshow_best(cubist_res, metric = \"rmse\")\n#> # A tibble: 5 × 8\n#>   committees neighbors .metric .estimator  mean     n std_err .config              \n#>        <int>     <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n#> 1         95         2 rmse    standard   4.592    10  0.2151 Preprocessor1_Model24\n#> 2         75         3 rmse    standard   4.610    10  0.2004 Preprocessor1_Model19\n#> 3         29         2 rmse    standard   4.617    10  0.2122 Preprocessor1_Model08\n#> 4         91         4 rmse    standard   4.619    10  0.1931 Preprocessor1_Model23\n#> 5         54         3 rmse    standard   4.620    10  0.1908 Preprocessor1_Model14\n\nshow_best(cubist_res, metric = \"rsq\", n = 3)\n#> # A tibble: 3 × 8\n#>   committees neighbors .metric .estimator   mean     n  std_err .config             \n#>        <int>     <int> <chr>   <chr>       <dbl> <int>    <dbl> <chr>               \n#> 1         95         2 rsq     standard   0.9244    10 0.007673 Preprocessor1_Model…\n#> 2         75         3 rsq     standard   0.9241    10 0.006887 Preprocessor1_Model…\n#> 3         54         3 rsq     standard   0.9239    10 0.006690 Preprocessor1_Model…\n```\n:::\n\n\n\n\nTo return the candidate with the smallest RMSE: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncubist_best <- select_best(cubist_res, metric = \"rmse\")\ncubist_best\n#> # A tibble: 1 × 3\n#>   committees neighbors .config              \n#>        <int>     <int> <chr>                \n#> 1         95         2 Preprocessor1_Model24\n```\n:::\n\n\n\n\nThere are a few things that we can do with this candidate value. We can use it to subset other results. For example, we can get the out-of-sample predictions _for just this model_ via: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncubist_res %>% \n  collect_predictions() %>% \n  nrow()\n#> [1] 19300\n\n# Just for the best:\ncubist_res %>% \n  collect_predictions(parameters = cubist_best) %>% \n  nrow()\n#> [1] 772\n\n# augment() returns the numerically best by default: \ncubist_res %>% \n  augment() %>% \n  nrow()\n#> [1] 772\n```\n:::\n\n\n\n\nWe can also give these values for the calibration plot produced by <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=probably\">probably</a></span>: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(probably)\ncal_plot_regression(cubist_res, parameters = cubist_best)\n```\n\n::: {.cell-output-display}\n![](../figures/reg-cal-best-1.svg){fig-align='center' width=50%}\n:::\n:::\n\n\n\n\nIf these candidate points appear to be optimal, we can also update our model specification (or workflow) using a `finalize_*()` function:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfinalize_model(cubist_spec, cubist_best)\n#> Cubist Model Specification (regression)\n#> \n#> Main Arguments:\n#>   committees = 95\n#>   neighbors = 2\n#> \n#> Computational engine: Cubist\n```\n:::\n\n\n\n\nIf we used the `save_workflow = TRUE` control option, we could get fit on the entire training set for this model via `fit_best()`, which serves as a shortcut  \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit_best(cubist_res)\n#> ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n#> Preprocessor: Formula\n#> Model: cubist_rules()\n#> \n#> ── Preprocessor ─────────────────────────────────────────────────────────────────────\n#> compressive_strength ~ .\n#> \n#> ── Model ────────────────────────────────────────────────────────────────────────────\n#> \n#> Call:\n#> cubist.default(x = x, y = y, committees = 95L)\n#> \n#> Number of samples: 772 \n#> Number of predictors: 8 \n#> \n#> Number of committees: 95 \n#> Number of rules per committee: 11, 13, 10, 10, 12, 10, 11, 12, 4, 13, 8, 16, 5, 23, 5, 14, 4, 15, 12, 13 ...\n```\n:::\n\n\n\n\nFinally, as previously seen in @sec-parallel-resamples, we can parallel process these model fits using the same syntax as shown there. \n\n## Racing\n\nThe syntax for these optimization methods is virtually the same. Besides the different function names, the control function has a few options of note: \n\n- `verbose_elim` should be a logical for whether a log of the candidate eliminations should be shown. \n- `burn_in` requires an integer and represents the earliest the parameter filter should be applied. \n- `num_ties`, also an integer value, decides when tie-breaking should occur when only two candidates are remaining. \n- `alpha`  is the numeric value for the hypothesis testing false positive rate (for one-sided hypothesis tests). \n- `randomize` accepts a logical value for whether the resamples should be randomly ordered. \n\nLet’s run the same Cubist grid using the ANOVA method: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(finetune)\n\n# Since resamples are randomized, set the seed:\nset.seed(11)\ncubist_race_res <- \n  cubist_spec %>% \n  tune_race_anova(\n    compressive_strength ~ .,\n    resamples = concrete_rs,\n    grid = cubist_grid,\n    control = control_race(verbose_elim = TRUE)\n  )\n#> ℹ Evaluating against the initial 3 burn-in resamples.\n#> ℹ Racing will minimize the rmse metric.\n#> ℹ Resamples are analyzed in a random order.\n#> ℹ Fold05: 12 eliminated; 13 candidates remain.\n#> \n#> ℹ Fold07: 8 eliminated; 5 candidates remain.\n#> \n#> ℹ Fold10: 1 eliminated; 4 candidates remain.\n#> \n#> ℹ Fold01: 0 eliminated; 4 candidates remain.\n#> \n#> ℹ Fold08: 0 eliminated; 4 candidates remain.\n#> \n#> ℹ Fold03: 0 eliminated; 4 candidates remain.\n#> \n#> ℹ Fold09: 0 eliminated; 4 candidates remain.\n```\n:::\n\n\n\n\nIt is important to note that the helpful functions for racing results mostly filter their output to disregard candidates who did not finish the race. For example, if we ask `show_best()` to  provide results for more candidate than those that finished, it will curtail its output: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nshow_best(cubist_race_res, metric = \"rmse\", n = 10)\n#> # A tibble: 4 × 8\n#>   committees neighbors .metric .estimator  mean     n std_err .config              \n#>        <int>     <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n#> 1         95         2 rmse    standard   4.592    10  0.2151 Preprocessor1_Model24\n#> 2         75         3 rmse    standard   4.610    10  0.2004 Preprocessor1_Model19\n#> 3         29         2 rmse    standard   4.617    10  0.2122 Preprocessor1_Model08\n#> 4         54         3 rmse    standard   4.620    10  0.1908 Preprocessor1_Model14\n```\n:::\n\n\n\n\nTo visualize the results, there is also a `plot_race()` function:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot_race(cubist_race_res)\n```\n\n::: {.cell-output-display}\n![](../figures/race-plot-1.svg){fig-align='center' width=60%}\n:::\n:::\n\n\n\n\nEach line corresponds to a candidate. \n\n## Nested Resampling {#sec-nested-resampling}\n\nThere are tidymodels experimental APIs for nested resampling (and analytical bias correction). We’ll fill this section in when these are finalized. \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}