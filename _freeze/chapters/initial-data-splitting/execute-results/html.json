{
  "hash": "5d5bdbb970092c44fb06ccdd4ae2373c",
  "result": {
    "engine": "knitr",
    "markdown": "---\nknitr:\n  opts_chunk:\n    cache.path: \"../_cache/initial-data-splitting/\"\n---\n\n# Initial Data Splitting {#sec-initial-data-splitting}\n\nWe'll illustrate how to conduct an initial split of your data into different partitions (used for different purposes). \n\n## Requirements\n\n\n\nYou’ll need 4 packages (<span class=\"pkg\"><a href=\"https://cran.r-project.org/package=caret\">caret</a></span>, <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=spatialsample\">spatialsample</a></span>, <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=tidymodels\">tidymodels</a></span>, and <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=tidysdm\">tidysdm</a></span>) for this chapter. \nYou can install them via:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nreq_pkg <- c(\"caret\", \"spatialsample\", \"tidymodels\", \"tidysdm\")\n\n# Check to see if they are installed: \npkg_installed <- vapply(req_pkg, rlang::is_installed, logical(1))\n\n# Install missing packages: \nif ( any(!pkg_installed) ) {\n  install_list <- names(pkg_installed)[!pkg_installed]\n  pak::pak(install_list)\n}\n```\n:::\n\n\nLet's load the meta package and manage some between-package function conflicts. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\n```\n:::\n\n\nThe data used here are both in R packages that are already installed. Let's work with the primary data set: the Ames Iowa housing data.\n\n## The Ames Housing Data {#sec-ames-intro}\n\nThese data are in the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=modeldata\">modeldata</a></span> package, which is part of  <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=tidymodels\">tidymodels</a></span>. Let's load the data, subset a few columns, and modify the sale price units. We'll also combine the two bathroom-related columns into a single column. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(ames, package = \"modeldata\")\n\names <-\n  ames %>%\n  select(Sale_Price, Bldg_Type, Neighborhood, Year_Built, Gr_Liv_Area, Full_Bath,\n         Half_Bath, Year_Sold, Lot_Area, Central_Air, Longitude, Latitude) %>%\n  mutate(\n    Sale_Price = log10(Sale_Price),\n    Baths = Full_Bath  + Half_Bath/2\n  ) %>%\n  select(-Half_Bath, -Full_Bath)\n\nglimpse(ames)\n#> Rows: 2,930\n#> Columns: 11\n#> $ Sale_Price   <dbl> 5.332, 5.021, 5.236, 5.387, 5.279, 5.291, 5.329, 5.282, 5.374…\n#> $ Bldg_Type    <fct> OneFam, OneFam, OneFam, OneFam, OneFam, OneFam, TwnhsE, Twnhs…\n#> $ Neighborhood <fct> North_Ames, North_Ames, North_Ames, North_Ames, Gilbert, Gilb…\n#> $ Year_Built   <int> 1960, 1961, 1958, 1968, 1997, 1998, 2001, 1992, 1995, 1999, 1…\n#> $ Gr_Liv_Area  <int> 1656, 896, 1329, 2110, 1629, 1604, 1338, 1280, 1616, 1804, 16…\n#> $ Year_Sold    <int> 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2010, 2…\n#> $ Lot_Area     <int> 31770, 11622, 14267, 11160, 13830, 9978, 4920, 5005, 5389, 75…\n#> $ Central_Air  <fct> Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y, Y…\n#> $ Longitude    <dbl> -93.62, -93.62, -93.62, -93.62, -93.64, -93.64, -93.63, -93.6…\n#> $ Latitude     <dbl> 42.05, 42.05, 42.05, 42.05, 42.06, 42.06, 42.06, 42.06, 42.06…\n#> $ Baths        <dbl> 1.0, 1.0, 1.5, 2.5, 2.5, 2.5, 2.0, 2.0, 2.0, 2.5, 2.5, 2.0, 2…\n```\n:::\n\n\ntidymodels requires that, for outcome data, any basic transformations should occur before data splitting. \n\n<a href=\"https://aml4td.org/chapters/initial-data-splitting.html#sec-ames-intro\" >{{< fa solid rotate-left size=small >}}</a>\n\n## Simple Data Splitting  {#sec-basic-splitting}\n\nThere are a few main functions for an initial split: \n\n - `rsample::initial_split()`: completely random splits and stratified splits. \n - `rsample::initial_time_split()`: non-random splits for times series; the most recent data are used for testing.\n - `rsample::initial_validation_split()` and `rsample::initial_validation_time_split()`: an initial split into three partitions. \n - `rsample::group_initial_split()`: for situations with repeated measures or other important grouping factors. \n \nMost of our applications will use the first function, where the default is to use 75% for training and 25% for testing. This is determined at random; there is no need to randomly sort the rows before splitting. By default, a simple random split is used. \n\nLet's do that with the Ames data:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(3024)\names_split <- initial_split(ames)\n\names_split\n#> <Training/Testing/Total>\n#> <2197/733/2930>\n```\n:::\n\n\nThe output shows the size of the resulting data sets. To get the two data sets, there are simple accessor functions: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\names_train <- training(ames_split)\names_test  <- testing(ames_split)\n```\n:::\n\n\nConsistent with the printed output, there are 2,197 data points in the training set and 733 reserved for testing. \n\nWe won't touch on `initial_time_split()` here but only mention that it takes the fraction of the data specified for testing from the bottom/tail of the data frame. Unlike the previous function, the order of the rows matters since the rows at the end of the data frame as used as the test set. \n\n`group_initial_split()` and `initial_validation_split()` are discussed in more detail below.\n\n<a href=\"https://aml4td.org/chapters/initial-data-splitting.html#sec-basic-splitting\" >{{< fa solid rotate-left size=small >}}</a>\n\n## Using the Outcome  {#sec-split-with-outcome}\n\nFor the Ames data, we know that the distribution of sale prices has some outlying points. To deal with this, we can use a stratified split (on the outcome) using 5 quantiles of the data in `ames`: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(3024)\names_block_split <- initial_split(ames, strata = Sale_Price, breaks = 5)\n\names_block_split\n#> <Training/Testing/Total>\n#> <2196/734/2930>\n```\n:::\n\n  \nNothing else changes; the same functions can be used to access the training and testing data. \n\n<a href=\"https://aml4td.org/chapters/initial-data-splitting.html#sec-split-with-outcome\" >{{< fa solid rotate-left size=small >}}</a>\n\n## Using the Predictors  {#sec-split-with-predictors}\n\nInstead of using the outcome to partition the data, other columns can be used when applicable. The text mentions using the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=twinning\">twinning</a></span> package ([CRAN page](https://cran.r-project.org/package=twinning)). The same authors have a second approach that can be found in the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=SPlit\">SPlit</a></span> package ([CRAN](https://cran.r-project.org/package=SPlit)). Both are straightforward to use. \n\nMaximum dissimilarity sampling can be conducted using `caret::maxDissim()`. It starts with an initial set of one or more or fewer data points to use as a starter. Unless there is a specific set of points of interest, picking one close to the center of the multivariate predictor distribution might make sense. Here is some code that uses the geographic coordinates as the splitting variables: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Since we will be using distances in the calculations, create centered \n# and scaled versions of the coordinates then add a row index column. \names_scaled <-\n  ames %>%\n  select(Longitude, Latitude) %>%\n  mutate(\n    scaled_lon = scale(Longitude)[,1], \n    scaled_lat = scale(Latitude)[,1]\n  ) %>%\n  select(starts_with(\"scaled\")) %>% \n  add_rowindex()\n\n# Select an initial data point closest to the middle\nseed_row <-\n  ames_scaled %>%\n  mutate(\n    dist = (scaled_lon)^2 + (scaled_lat)^2\n  ) %>%\n  slice_min(dist, n = 1) %>%\n  pluck(\".row\")\n\n# Partition the data\names_scaled_seed <- ames_scaled %>% slice( seed_row)\names_scaled_pool <- ames_scaled %>% slice(-seed_row)\n\n# Conduct the selection process\nselection_path <- \n  caret::maxDissim(\n    # Only give the function the predictor columns for each data set\n    ames_scaled_seed %>% select(-.row), \n    ames_scaled_pool %>% select(-.row), \n    n = 24\n  )\n\n# Get the selected row numbers that correspond to the 'ames' data frame.\nselected_rows <- c(seed_row, ames_scaled_pool$.row[selection_path])\n\nselected_data <- ames %>% slice(selected_rows)\n\n# A non-map plot of the values: \nselected_data %>%\n  mutate(xend = lead(Longitude), yend = lead(Latitude)) %>%\n  ggplot(aes(Longitude, Latitude)) +\n  geom_point() +\n  geom_segment(aes(xend = xend, yend = yend),\n               arrow = arrow(length = unit(0.1, \"inches\"), type = \"closed\"),\n               col = \"blue\", alpha = 1 / 5) +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](../figures/ames-dissim-1.svg){fig-align='center' width=50%}\n:::\n:::\n\n\n<a href=\"https://aml4td.org/chapters/initial-data-splitting.html#sec-split-with-predictors\" >{{< fa solid rotate-left size=small >}}</a>\n\n## Validation Sets  {#sec-three-way-split}\n\nTo add a validation set at the outset, `initial_validation_split()` works the same as `initial_split()`. The `prop` argument requires _two values_ now: the first is the training set proportion, and the second is for the validation set. In this example below, we add 80% to training, 10% to validation, and the remaining 10% to the testing set: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(4)\names_val_split <- initial_validation_split(ames, strata = Sale_Price, prop = c(0.8, 0.1))\n\names_val_split\n#> <Training/Validation/Testing/Total>\n#> <2342/293/295/2930>\n```\n:::\n\n\nAgain, the acquisition of data is the same but has the additional use of the `validation()` function: \n \n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\names_train <- training(ames_val_split)\names_val   <- validation(ames_val_split)\names_test  <- testing(ames_val_split)\n```\n:::\n\n\n`rsample::initial_validation_time_split()` does the same thing but based on the ordering of the data (as opposed to random selection). \n\nSuppose a data frame had 100 rows. Using `prop = c(0.8, 0.1)` would place the first 80 rows into training, the next 10 into validation, and the last 10 into testing. Keeping the data appropriately ordered is important when using validation sets in tidymodels. \n\n<a href=\"https://aml4td.org/chapters/initial-data-splitting.html#sec-three-way-split\" >{{< fa solid rotate-left size=small >}}</a>\n\n## Multi-Level Data  {#sec-multilevel-splitting}\n\nThis section will focus on data with a rational grouping of data. For example, medical data might follow patient over time so that there are multiple rows per patient. The patient is the independent experimental unit (IEU), meaning that the data between patients are thought to be independent, and those within a patient are (statistically) related. We want to partition the data so that all of the data for each IEU end up in _either_ the training or test sets but not both. We want to sample the data by the group -- where the group in this example is the patient. \n\nThere are other applications of grouped data but the example data that we'll use fits into the description above: 27 patients were followed and had data collected at four time points. The data are in the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=nlme\">nlme</a></span> package:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndata(Orthodont, package = \"nlme\")\nglimpse(Orthodont)\n#> Rows: 108\n#> Columns: 4\n#> $ distance <dbl> 26.0, 25.0, 29.0, 31.0, 21.5, 22.5, 23.0, 26.5, 23.0, 22.5, 24.0,…\n#> $ age      <dbl> 8, 10, 12, 14, 8, 10, 12, 14, 8, 10, 12, 14, 8, 10, 12, 14, 8, 10…\n#> $ Subject  <ord> M01, M01, M01, M01, M02, M02, M02, M02, M03, M03, M03, M03, M04, …\n#> $ Sex      <fct> Male, Male, Male, Male, Male, Male, Male, Male, Male, Male, Male,…\n```\n:::\n\n\nTo use `rsample::group_initial_split()`, we must supply a `group` argument that corresponds to one of the columns in the data. There is also a `prop` argument that specifies the proportion of the groups that should go into the training set. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(93)\north_split <- group_initial_split(Orthodont, group = Subject, prop = 2 / 3)\n\n# The numbers in this output are individual rows (not numbers of groups)\north_split\n#> <Training/Testing/Total>\n#> <72/36/108>\n```\n:::\n\n\nFrom here, the code to get the resulting data sets is the same as previously shown. We'll also verify that no subjects are in both data sets: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\north_tr <- training(orth_split)\north_te  <- testing(orth_split)\n\n# Is there any overlap in the subjects? \nsubjects_train <- unique(orth_tr$Subject)\nsubjects_test  <- unique(orth_te$Subject)\n\nintersect(subjects_train, subjects_test)\n#> ordered()\n#> 27 Levels: M16 < M05 < M02 < M11 < M07 < M08 < M03 < M12 < M13 < M14 < ... < F11\n```\n:::\n\n\n<a href=\"https://aml4td.org/chapters/initial-data-splitting.html#sec-multilevel-splitting\" >{{< fa solid rotate-left size=small >}}</a>\n\n## Splitting Spatial Data {#sec-spatial-splitting}\n\nFor spatial data, we need to convert longitude and latitude to a special type of vector called a [geometry](https://r-spatial.github.io/sf/reference/st_geometry.html) vector. The <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=sf\">sf</a></span> package can do this so let's load that and two others:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(sf)\n#> Linking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\nlibrary(spatialsample)\nlibrary(tidysdm)\n```\n:::\n\n\nThe function to make the conversion is `sf::st_as_sf()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\names_sf <-\n  ames %>%\n  st_as_sf(coords = c(\"Longitude\", \"Latitude\"), crs = 4326)\n\names_sf %>% select(geometry)\n#> Simple feature collection with 2930 features and 0 fields\n#> Geometry type: POINT\n#> Dimension:     XY\n#> Bounding box:  xmin: -93.69 ymin: 41.99 xmax: -93.58 ymax: 42.06\n#> Geodetic CRS:  WGS 84\n#> # A tibble: 2,930 × 1\n#>         geometry\n#>      <POINT [°]>\n#> 1 (-93.62 42.05)\n#> 2 (-93.62 42.05)\n#> 3 (-93.62 42.05)\n#> 4 (-93.62 42.05)\n#> 5 (-93.64 42.06)\n#> 6 (-93.64 42.06)\n#> # ℹ 2,924 more rows\n```\n:::\n\n\nThe `crs` argument specifies a [coordinate reference system](https://en.wikipedia.org/wiki/Spatial_reference_system). We used [4326](https://spatialreference.org/ref/epsg/4326/) since it contains the US. \n\nNote that this is a _sticky_ column and can't be removed via normal means. There is a function to do this though: `sf::st_drop_geometry()`. \n\nThe <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=tidysdm\">tidysdm</a></span> package can create an initial data split using the methods given in the <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=spatialsample\">spatialsample</a></span> package. The function is `tidysdm::spatial_initial_split()`.  The main argument is `prop` for the amount of data in the _testing_ set. Let’s put 20% into testing using `prop = 0.2`. \n\nAfter specifying this, we can set a blocking strategy using <span class=\"pkg\"><a href=\"https://cran.r-project.org/package=spatialsample\">spatialsample</a></span>, such as: \n \n - `spatial_block_cv()`: create a regular grid. \n - `spatial_clustering_cv()`: use a clustering method to group the data. \n\nFor the blocking method, we need to specify the number of blocks (`n`), whether the block is square or hexagonal (`square`), and (optionally) the radius for a buffer (`buffer`). These options will define how to create blocks. There is another option that designates how the blocks are assigned to the training set: `method`. You should experiment with these for your data. We’ll use `method = \"continuous\"` in this example. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(318)\names_block_split <-\n  spatial_initial_split(\n    ames_sf, \n    prop = 0.2, \n    strategy = spatial_block_cv,\n    method = \"continuous\",\n    n = 25, \n    square = FALSE)\names_block_split\n#> <Training/Testing/Total>\n#> <2326/604/2930>\n```\n:::\n\n\nThere is a handy `autoplot()` method to visually assess the results: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(ames_block_split, cex = 1 / 2) + \n  ggtitle(\"Blocking, no buffer\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](../figures/ames-split-block-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n\nLet's add a buffer around these blocks to stop adjacent data from being the training and testing sets. We can experiment with the `buffer` argument until we have results that seem acceptable. \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nset.seed(318)\names_block_buff_split <-\n  spatial_initial_split(\n    ames_sf, \n    prop = 0.2, \n    strategy = spatial_block_cv,\n    method = \"continuous\",\n    n = 25, \n    square = FALSE,\n    buffer = 250)\names_block_buff_split\n#> <Training/Testing/Total>\n#> <1587/604/2930>\n```\n:::\n\n\nThe buffer points are on gray: \n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nautoplot(ames_block_buff_split, cex = 1 / 2) + \n  ggtitle(\"Blocking with a buffer\") + \n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](../figures/ames-split-block-buff-1.svg){fig-align='center' width=70%}\n:::\n:::\n\n\nAs with the previous methods, the `training()` and `testing()` functions are used to obtain those data sets. \n\n<a href=\"https://aml4td.org/chapters/initial-data-splitting.html#sec-spatial-splitting\" >{{< fa solid rotate-left size=small >}}</a>\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}